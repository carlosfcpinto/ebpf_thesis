    
\chapter{Problem Statement, Experiments and Work Plan}

\section{Introduction}
The Problem Statement, Proposed Solution, Experiments, and Work Plan chapter is a crucial component of the thesis as it outlines the research problem, a possible solution to it, an experiment to further sustain that solution, and the plan for executing the research. In this chapter, we aim to present a clear and concise description of the problem we are solving, why it is important, and why the proposed solution is a valid one. The chapter will also include a detailed description of the experiments that will be conducted to validate the solution, as well as the work plan that outlines the tasks and the timeline for executing the research.

\section{The Problem}

A common data exfiltration definition is the theft or unauthorized removal or movement of any data from a device, typically involving a cyber criminal stealing data from personal or corporate devices. 
The definition more relevant to this dissertation is that of data exportation and extrusion, posing serious problems for organizations. Failing to control information security could mean the loss of intellectual property or cause reputational and financial damage to an organization. 

The problem being faced is that of preventing data exfiltration inside virtual machines. 
This problem has seen various approaches to being solved, such as static configurations, which work best when configured statically during the provisioning of a machine, becoming brittle to operate when deployed across a fleet of machines and in the face of changing policies.


\section{Proposed Solution}
The proposed solution aims to tackle the challenges mentioned in the previous section by providing a method of easily load tools with the intention of preventing data exfiltration, leakage or theft. To achieve this, the solution leverages the advantages of kernel based security, as well as the flexibility and ease of use of eBPF. 

By using these approaches, the focus of this solution is the ease of deployment and verified security that eBPF provides. 

The main object of this thesis is the development of an eBPF application preventing data exfiltration from virtual machines, such that one policy can be extended across various machines. As stated above, the classical approach of static configurations, although working when configured statically during the provisioning of the machine, become hard to operate when deployed across a fleet of machines. 

This solution will serve the purpose of restricting services and capabilities inside the kernel, based on a per user or service approach, effectively armoring the system from unwanted accesses, either to services or files, preventing data exfiltration from said machines.

The resulting application would then go through a formal verification process on the kernel side of the application, ensuring that the rules to be applied are only that. 

As of the writing of this document, there's no knowledge of projects or documents that describe a similar solution to the one proposed. There are several eBPF based tools for security purposes, mentioned in the previous chapter, but none of these leverage formal verification, and as such, this solution presents itself as both an academic and business opportunity.

The choice to formally verify this tool aims at ensuring the safety and correctness of said program. eBPF programs, although already a subject of formal methods through the verifier, do not currently ensure with absolute certainty the safety and correctness of the implementation attempted. 

In the next section, an experiment will be demonstrated to showcase the feasibility and practicality of our objective. This first study is designed to validate our ideas and provide a foundation for future development. While we did not develop a full-fledged tool, this experiment serves as a crucial first step in demonstrating that there's a potential for the use of eBPF to prevent data exfiltration and leakage. 

In conclusion, the solution proposes to overcome the challenges mentioned in the previous section by providing a method of dynamically implement security policies, enforced at kernel level, to a fleet of machines, without the hassle needed with classical methods.


\section{Experiments}

eBPF has proven itself as a flexible and secure tool for security and observability. The experiment aims to test and demonstrate the capabilities of this tool, by reacting to certain system calls, identifying the user who made it and where it came from, with the purpose of, in the future, extend it to not only present the system call made but to also act upon it, potentially preventing data exfiltration using this method. In this section we will elaborate on why eBPF is an ideal fit for this experiment and explore the inner workings of it.

The experiment at hand involves the implementation of an eBPF program, both user side and kernel side code, using the CO-RE approach, so that when a call is made to \texttt{chdir} is made the program will present the contents of said folder and identify the user who made the call, essentially behaving as an \texttt{ls} command. 

We will also delve into the files that make up a typical eBPF application and explain how the program was developed based on the CO-RE approach. 

In conclusion, this experiment will serve as a demonstration of eBPF's capability from a security stand point. 

\subsection{\textbf{eBPF implementation of \texttt{ls}}}

This experiment proved itself relevant as a means to be more familiarized with eBPF's typical struccture as well as its capabilities. 
To achieve that goal, it is important to understand the different files involved in such applications. Normally, there will be a file for the kernel side of the application, as well as one for the user side. We shall call these \texttt{eBPF\_ls.bpf.c} and \texttt{eBPF\_ls.c} for the kernel side and the user side, respectively. 

\subsubsection{\texttt{eBPF\_ls.bpf.c}}
\texttt{eBPF\_ls.bpf.c} will contain the code meant to be run at kernel level, meaning that it can define a hookpoint to a certain system call. This is achieved by 


\begin{lstlisting}
    SEC("ksyscall/chdir")
\end{lstlisting}
which defines that we are only interested in running this program when a system call to \texttt{chdir} is made. 

Hence, when such system call is made this program is triggered. The program then acts accordingly. 

\begin{lstlisting}
    int BPF_KPROBE_SYSCALL(hello, const char *name){
        struct data_t data = {};
        struct user_msg_t *p; 
\end{lstlisting}
In the above code snippet we make use of the \texttt{BPF\_KPROBE\_SYSCALL} macro defined in \texttt{libbpf} that allows to acces the argument of a system call by name. The only argument the \texttt{chdir} accepts is the name of the destin directory. We can the write the data accessed to a perf buffer so that is accessible in the user side of the application. 

\begin{lstlisting}
    data.pid = bpf_get_current_pid_tgid() >> 32;
    data.uid = bpf_get_current_uid_gid() & 0xFFFFFFFF;

    bpf_probe_read_user_str(&data.path, sizeof(data.path), name);
\end{lstlisting}
The first two lines are used so that we can access the process id and the user id that made the system call. 
The \texttt{bpf\_probe\_read\_user\_str} is an helper function that copies data from an unsafe address to the perf buffer output, in this case containing the argument to the \texttt{chdir} system call, the process id and user id from where the call was made.
After the data has been written, we can then share it with user space code using the following line: 
\begin{lstlisting}
bpf_perf_event_output(ctx, &output, BPF_F_CURRENT_CPU, &data, sizeof(data));
\end{lstlisting}
This helper function writes the data into the perf buffer output, making it accessible from user space. 
Finally, there is another macro defining a license string, being a crucial requirement for eBPF programs. 
\begin{lstlisting}
    char LICENSE[] SEC("license") = "Dual BSD/GPL";
\end{lstlisting}

This sums up the steps need in the kernel side of the application, creating a \texttt{kprobe} to the \texttt{chdir} system call, and sending the directory that made the call to the user side of the application. 

\subsubsection{\texttt{eBPF\_ls.c}}
\texttt{eBPF\_ls.c} will contain the code to be run in user space, reacting to the data sent from the kernel side of the application. It will start by loading the BPF skeleton, containing handy functions to manage the lifecycle of the program, such as loading it into the kernel. 
\begin{lstlisting}[numbers=left]
int main() {
  struct eBPF_ls_bpf *skel;
  int err;
  struct perf_buffer *pb = NULL;

  libbpf_set_print(libbpf_print_fn);

  skel = eBPF_ls_bpf__open_and_load();
  if (!skel) {
    printf("Failed to open BPF object\n");
    return 1;
  }

  err = eBPF_ls_bpf__attach(skel);
  if (err) {
    fprintf(stderr, "Failed to attach BPF skeleton: %d\n", err);
    eBPF_ls_bpf__destroy(skel);
    return 1;
  }

\end{lstlisting}

Line 8 in the code snippet above creates a \texttt{skel} structure representing all the maps and programs defined in the ELF bytes, loading them into the kernel. Line 14 attaches the program to the appropriate event, returning and error if it was unsuccessful.
We can then create a structure to handle the perf buffer output, as presented below. 
\begin{lstlisting}[numbers=left]
pb = perf_buffer__new(bpf_map__fd(skel->maps.output), 8, handle_event,
                      lost_event, NULL, NULL);
if (!pb) {
  err = -1;
  fprintf(stderr, "Failed to create ring buffer\n");
  eBPF_ls_bpf__destroy(skel);
  return 1;
}
\end{lstlisting}
The \texttt{handle\_event} and \texttt{lost\_event} are functions that handle the events captured when polling the perf buffer. 
The perf buffer will then be continuously polled: 
\begin{lstlisting}[numbers=left]
while (true) {
    err = perf_buffer__poll(pb, 10000000 /* timeout, ms */);
    // Ctrl-C gives -EINTR
    if (err == -EINTR) {
      err = 0;
      break;
    }
    if (err < 0) {
      printf("Error polling perf buffer: %d\n", err);
      break;
    }
  }
\end{lstlisting}

When there is an event in the perf buffer output, we can expect to find the name of the directory that was passed to the \texttt{chdir} system call, as well as the user id that made the system call. As such, the \texttt{handle\_event} function is triggered, and we can then iterate over the directory to display its files. 
\begin{lstlisting}[numbers=left]
void handle_event(void *ctx, int cpu, void *data, unsigned int data_sz) {
  struct data_t *m = data;
  char *pad = "{ ";
  if (!strcmp(m->command + strlen(m->command) - 2, "sh")) {
    const char *dir_path = m->path;
    DIR *dir = opendir(dir_path);

    // Check if the directory can be opened
    if (!dir) {
      perror("opendir");
    }

    struct dirent *entry;

    printf("%s: ", getUser(m->uid));
    // Read and print the contents of the directory
    while ((entry = readdir(dir)) != NULL) {
      printf("%s%s", pad, entry->d_name);
      pad = ", ";
    }
    printf("}\n");
    closedir(dir);
    printf("\n\n\n\n");
  }
}
\end{lstlisting}
We print the user id that made the system call and then print the contents of the directory that said user is changing to.


\subsubsection{Makefile}
The Makefile for this application, being based on the CO-RE approach has several options that are worth digging into. 
First off, when compiling both the user side and kernel side it is needed to pass the \texttt{\-g} flag to the Clang compiler, so that it includes debug information, that is necessary for BTF. The \texttt{\-O2} optimization flag also needs to be passed, in order for Clang to produce BPF bytecode that can pass the verification process. The target architecture needs to be specified in order to use certain macros defined in \texttt{libbpf}. Joining all of these we achieve the following to build BPF code:
\begin{lstlisting}
%.bpf.o: %.bpf.c vmlinux.h
	clang \
	    -target bpf \
        -D __TARGET_ARCH_$(ARCH) \
	    -Wall \
	    -O2 -g -o $@ -c $<
	llvm-strip -g $@
\end{lstlisting}

We then need to generate BPF skeletons, which contain several useful functions to handle the lifecycle of the program, we use \texttt{bpftool} to achieve this, which uses the eBPF object in ELF file format to generate said skeletons. 
\begin{lstlisting}
$(USER_SKEL): $(BPF_OBJ)
	bpftool gen skeleton $< > $@
\end{lstlisting}

We then generate the header file \texttt{vmlinux.h}, containing all the data structure information about the kernel that is needed in a BPF program. 

\begin{lstlisting}
vmlinux.h:
	bpftool btf dump file /sys/kernel/btf/vmlinux format c > vmlinux.h
\end{lstlisting}

Lastly, we can build the user space code, using the line: 
\begin{lstlisting}
eBPF_ls: eBPF_ls.c
	gcc -Wall -o eBPF_ls eBPF_ls.c -L../libbpf/src -l:libbpf.a -lelf -lz
\end{lstlisting}

The typical structure for an eBPF application based on the CO-RE consists then of these three files, containing the eBPF program itself, the user side code and the Makefile specific to the application.

\subsection{Conclusion}
With this experiment, we were able to delve deeper into eBPF's capabilities, presenting a crude example of what is the goal of this dissertation, proving the usability of eBPF from a security standpoint. An application that monitors the \texttt{chdir} system call was developed, showing the target directory and the user who made the system call. 

\section{Future Tasks}
The plan outlined below highlights the tasks inteded to take place in this dissertation project. It should however be noted that the direction of the project may evolve and change as we progress, leading to potential modifications to the plan. Nonetheless, this serves as a starting point for the remainder of the project. 

\textbf{Task 1:} Implementation of an eBPF application capable of preventing data exfiltration, based on user specific policies, restraining certain files or processes from said users. The policies will be implemented in a specific format, so that they can change without having the need to hard code restricted users. 

\textbf{Task 2:} Testing the application. In this step the application will undergo rigorous testing so as to be deployed across a fleet of machines with some certainty that it works as intended.

\textbf{Task 3:} Formal verification of the application. This step will involve the design of a formal verification tool to verify eBPF code. Some approaches are to be considered, but to date only the verifier has been subject to formal verification using Coq. In this step we will continue to build on the knowledge gained from the development of the application to gain a clear overview of the best approach to formal verification. 

\textbf{Task 4:} Writing of the thesis. The thesis will present the research results and provide conclusions based on the work performed in the previous tasks. The writing of the thesis will be a final step, but will be done concurrently with the other tasks.

In addition to these tasks, additional features or improvements to existing ones might be added, depending on the results obtained. the aim is to continue advancing the state of the art in the field of eBPF security and particularly the formal verification of such tools.


\section{Conclusion}
In conclusion, this project has explored the crucial concepts of eBPF-based security. Through a review of the state of the art, it was made clear that although several tools leverage eBPF for security purposes, none of those have gone through the process of formal verification. 

The proposed solution is to develop an eBPF based tool, and submit it to the process of rigorous testing and formal verification, as to guarantee the safety and correctness of said tool. The experiment presented is to be seen as a first step in achieving this goal. 

The document also outlined the main contributions, goals, and objectives for future work. 
The next phase of the project will focus on the completion and testing of the target eBPF application, the formal verification process of it, leaving open the possibility of additional features and targets to be presented along the way. The aim is to advance the state of the art in the security field, specifically on data exfiltration prevention.
\begin{comment}
In addition to these tasks, we may consider incorporating additional features or making improvements to existing features, depending on the results of our research and the progress of our work. The aim is to continue advancing the state of the art in the field of blockchain consensus algorithms, and to provide a comprehensive understanding of the various protocols and tools that are available for improving the performance and efficiency of blockchain networks.


\section{Conclusion}

In conclusion, this project has explored the crucial concepts of in the field of blockchain technology. Through a review of the state of the art, it was revealed that there are several popular consensus algorithms used in blockchain networks, each with its own strengths and weaknesses. The project then identified the challenges in the field of consensus protocols, including the lack of standardization, difficulties in comparison, testing and the fact that there's a multitude of different consensus algorithms available in the field of blockchain technology,
making it difficult for individuals and organizations to adopt blockchain effectively.

The proposed solution was to overcome these challenges by providing a method of testing and easily swapping consensus algorithms in a pre-existing well-tested blockchain network.
The implementation of this solution was tested and proved to be feasible by the execution of the experiment done, demonstrating the versatility and flexibility of the Tezos network in accommodating custom consensus protocols.

The document also outlined the main contributions, goals, and objectives for future work.
The next phase of the project will focus on the completion and testing of the Proof of Work (experiment) protocol implemented in Tezos, development of a generic framework for adding new consensus algorithms, creation of a platform for testing them, integration with the Lupin DSL, and writing of the thesis to present research results and conclusions on the work performed. The aim is to advance the state of the art in blockchain consensus algorithms and provide a comprehensive understanding of available protocols and tools to improve block\-chain network performance and efficiency.





\end{comment}
